{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB.Polypeptide import d1_to_index\n",
    "from rdkit.Chem import AllChem\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import csv\n",
    "from Bio import Entrez\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_info (patterm,database=\"Gene\"):\n",
    "    '''download information from relervant database'''\n",
    " \n",
    "    handle = Entrez.esearch(db=database, term=patterm, retmax=500)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    " \n",
    "    return record\n",
    "\n",
    "def download_seq (id_array):\n",
    "    '''HAVE GeneID to download seqs'''\n",
    " \n",
    "    result_handle = Entrez.efetch(db=\"nucleotide\", rettype=\"fasta\",  id=id_array,retmode=\"text\")\n",
    "    result = result_handle.read()\n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Screen for biosensor sequences \"\"\"\n",
    "# List of detectable chemicals from https://github.com/brsynth/detectable_metabolites\n",
    "file_info = 'detectable_metabolites_current.csv'\n",
    "file_output = 'detectable_metabolites_seq.csv'\n",
    "Entrez.email = 'dr413677671@gmail.com'\n",
    "\n",
    "#with open(file_info) as header_input, open(file_output, 'w') as header_output:\n",
    "#    cw = csv.writer(header_output)\n",
    "#    cw.writerow( ('Name', 'Inchi', 'Gene', 'Organism', 'NCBI_Gene', 'Name', 'Description', 'Comment', 'Annotation') )\n",
    "#    cv = csv.DictReader( filter( lambda row: row[0] != '#', header_input ) )\n",
    "cv=pd.read_csv(file_info,header=0,sep=',')\n",
    "#    counter=0\n",
    "record=[]\n",
    "\n",
    "# eliminate unuseful columns\n",
    "cv.drop(['Reference', 'TypeOfExperiment','Comments','TypeOfDetection'], axis=1,inplace=True)\n",
    "# Change columns names\n",
    "cv.rename(columns={'DetectedBy':'Sensor'}, inplace = True)\n",
    "\n",
    "info=[]\n",
    "id_info=[]\n",
    "seq = []\n",
    "\n",
    "for index, row in cv.iterrows():\n",
    "    name = str(row['Name'])\n",
    "    inchi = row['InChI']\n",
    "    organism = str(row['Organism'])\n",
    "    sensor = str(row['Sensor'])\n",
    "    # Query based on gene name\n",
    "    # TO DO: curate generic names (riboswitch, TF, etc.)\n",
    "    if len(sensor) > 0:\n",
    "        # Query NCBI by gene name\n",
    "        term = []\n",
    "        term.append( sensor+'[GN]' )\n",
    "        if organism!= 'nan':\n",
    "            term.append( 'AND' )\n",
    "            term.append( organism+'[ORGN]' )\n",
    "        term = ' '.join(term)\n",
    "        try:\n",
    "            record=download_info(term,database=\"Gene\") \n",
    "        except:\n",
    "            continue\n",
    "        # Fetch the full record or just the summary (should be enough)\n",
    "        # Things to do:\n",
    "        # - Select the most convenient format (xml, etc.)\n",
    "        # - Query by name to avoid false hits\n",
    "        # - Use Description to double check transcriptional activity\n",
    "        # - Double-check organims (better through postprocessing)\n",
    "        if  record['IdList']:\n",
    "            id_array = record['IdList'][0]\n",
    "            id_info.append(id_array)\n",
    "            try:\n",
    "                infotmp,seqtmp=np.squeeze(re.findall(r'>(.*)\\n([\\s\\S]*$)',string))\n",
    "                info.append(infotmp)\n",
    "                seq.append(seqtmp)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            info.append(\"\")\n",
    "            seq.append(\"\")\n",
    "            id_info.append(\"\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence',\n",
       " 'T88334.1 12030 Lambda-PRL2 Arabidopsis thaliana cDNA clone 160P21T7, mRNA sequence']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search 101 sensors only 12 results\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add genes info as new columns to dataframe\n",
    "cv['info']=info\n",
    "cv['id']=id_info\n",
    "cv['seq']=seq\n",
    "\n",
    "# write csv\n",
    "file_output = 'detectable_metabolites_seq2.csv'\n",
    "cv.to_csv(file_output,index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4098\n"
     ]
    }
   ],
   "source": [
    "# Count the nonempty seqs num\n",
    "counter=0\n",
    "for i in seq:\n",
    "    if i:\n",
    "        counter=counter+1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             except:\n",
    "#                 continue\n",
    "            \n",
    "# #                h2 = Entrez.esummary(db='Gene', id=rid, retmode='text')\n",
    "# #                r2 = [x for x in h2]\n",
    "#                 r1 = [x.rstrip() for x in h1] \n",
    "#                 if re.findall(sensor, r1[2]):\n",
    "#                     try:\n",
    "#                         h3 = Entrez.efetch(db='sequences', id=rid, rettype='fasta')\n",
    "#                     except:\n",
    "#                         continue\n",
    "#                     out = ( name, inchi, sensor, organism, rid, r1[1], r1[2], r1[5], r1[4] )\n",
    "#                     print(out)\n",
    "#                     cw.writerow( out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readfasta(ffile):\n",
    "    \"\"\" Read fast file, return dictionary \"\"\"\n",
    "    record_dict = SeqIO.to_dict(SeqIO.parse(ffile, \"fasta\"))\n",
    "    return record_dict\n",
    "\n",
    "def tensorSeq(seqs, MAX_SEQ_LENGTH, SEQDEPTH, TOKEN_SIZE=20):\n",
    "    \"\"\" Encode an amino acid sequence as a tensor \n",
    "    by concatenating one-hot encoding up to desired depth \"\"\"\n",
    "    TRAIN_BATCH_SIZE = len(seqs)\n",
    "    Xs = np.zeros( (TRAIN_BATCH_SIZE, MAX_SEQ_LENGTH, SEQDEPTH*TOKEN_SIZE) )\n",
    "    for i in range(0, len(seqs)):\n",
    "        aaix = aaindex( seqs[i] )\n",
    "        for l in range(0, MAX_SEQ_LENGTH):\n",
    "            for k in range(0, SEQDEPTH):\n",
    "                try:\n",
    "                    Xs[i, l, aaix[l+k] + TOKEN_SIZE*k] = 1\n",
    "                except:\n",
    "                    continue\n",
    "    \"\"\" Flip sequences (zero-padding at the start) \"\"\"\n",
    "    Xsr = np.flip( Xs, 1 )\n",
    "    return Xsr, Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaindex(seq):\n",
    "    \"\"\" Convert amino acid to numerical index \"\"\"\n",
    "    ix = []\n",
    "    for a in seq:\n",
    "        if a in d1_to_index:\n",
    "            ix.append( d1_to_index[a] )\n",
    "    return ix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
